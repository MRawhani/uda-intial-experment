{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37d1b299-983c-4343-8d5e-02228d4b02b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'anyone else instead of sleeping more when depressed stay up all night to avoid the next day from coming sooner may be the social anxiety in me but life is so much more peaceful when everyone else is asleep and not expecting thing of you', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"mrjunos/depression-reddit-cleaned\")\n",
    "print(dataset['train'][2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7671a12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside a virtual environment\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix):\n",
    "    print(\"Inside a virtual environment\")\n",
    "else:\n",
    "    print(\"Not inside a virtual environment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0266ae-c9ca-4d23-9c30-319a4ca3ce39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/adapter-domain-adaptation-_0c-qnvO-py3.8/lib/python3.8/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2210bad6874a6790f3f9e5bc55a61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097fee931baf453894224cb34e2ff4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7efef7d59a4241df81b949b493606949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1824df6311d942f38b3c94e65ba66e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, input_data):\n",
    "        self.labels = [data for data in input_data['label']]\n",
    "        self.texts = [tokenizer(data,\n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for data in input_data['text']]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e819c3d2-df08-4273-b9b4-b41e19d75839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/adapter-domain-adaptation-_0c-qnvO-py3.8/lib/python3.8/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, model_id='bert-base-cased', num_class=2):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained(model_id, num_labels=num_class)\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7eccb3c-3249-400a-9bda-3774701ddec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e998f3d5-1874-4361-962c-dde149ae4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    # Fetch training and validation data in batch\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "       model = model.to(device)\n",
    "       criterion = criterion.to(device)\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        \n",
    "        # Fine-tune the model\n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)[0]\n",
    "\n",
    "            batch_loss = criterion(output, train_label.long())\n",
    "            total_loss_train += batch_loss.item()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "        \n",
    "        # Validate the model\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for val_input, val_label in val_dataloader:\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)[0]\n",
    "\n",
    "                batch_loss = criterion(output, val_label.long())\n",
    "                total_loss_val += batch_loss.item()\n",
    "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "\n",
    "        print(\n",
    "            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train): .3f} \\\n",
    "            | Train Accuracy: {total_acc_train / len(train): .3f} \\\n",
    "            | Val Loss: {total_loss_val / len(val): .3f} \\\n",
    "            | Val Accuracy: {total_acc_val / len(val): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d876019c-0455-4c6c-8300-ca0daf4c25e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b448b629364b04ab139f5bdd901715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "LR = 1e-7\n",
    "\n",
    "model = BertClassifier()\n",
    "data = dataset['train'].shuffle(seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "945d1b1e-23ef-42c2-9233-84e38061dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = Dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee19dc-75ee-4b25-aec9-c7acc90f9e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c4154af-d4da-4b0e-b37b-d7e72ec9e7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [04:21<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.234             | Train Accuracy:  0.816             | Val Loss:  0.167             | Val Accuracy:  0.890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [04:23<00:00, 12.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.148             | Train Accuracy:  0.903             | Val Loss:  0.129             | Val Accuracy:  0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [04:25<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.113             | Train Accuracy:  0.931             | Val Loss:  0.099             | Val Accuracy:  0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [04:25<00:00, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.084             | Train Accuracy:  0.950             | Val Loss:  0.074             | Val Accuracy:  0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [04:25<00:00, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.065             | Train Accuracy:  0.962             | Val Loss:  0.060             | Val Accuracy:  0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [04:25<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss:  0.052             | Train Accuracy:  0.970             | Val Loss:  0.052             | Val Accuracy:  0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [04:25<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss:  0.043             | Train Accuracy:  0.975             | Val Loss:  0.048             | Val Accuracy:  0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [04:25<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss:  0.036             | Train Accuracy:  0.979             | Val Loss:  0.046             | Val Accuracy:  0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [04:25<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss:  0.031             | Train Accuracy:  0.983             | Val Loss:  0.044             | Val Accuracy:  0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [04:25<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 | Train Loss:  0.026             | Train Accuracy:  0.986             | Val Loss:  0.043             | Val Accuracy:  0.969\n"
     ]
    }
   ],
   "source": [
    "train(model, data[:6500], data[6500:], LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0883b51b-46d9-47dc-acc8-78d3782b4c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 108311810 || all params: 108311810 || trainable%: 100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntrainable params: 108311810 || all params: 108311810 || trainable%: 100.0\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "print_trainable_parameters(model)\n",
    "'''\n",
    "trainable params: 108311810 || all params: 108311810 || trainable%: 100.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e426e715-8da3-4a3b-b36b-a25abbbe8101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/adapter-domain-adaptation-_0c-qnvO-py3.8/lib/python3.8/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from adapters import AdapterConfig\n",
    "from adapters import BertAdapterModel\n",
    "\n",
    "class BertClassifierWithAdapter(nn.Module):\n",
    "\n",
    "    def __init__(self, model_id='bert-base-cased', adapter_id='pfeiffer', \n",
    "                task_id = 'depression_reddit_dataset', num_class=2):\n",
    "\n",
    "        super(BertClassifierWithAdapter, self).__init__()\n",
    "\n",
    "        self.adapter_config = AdapterConfig.load(adapter_id)\n",
    "\n",
    "        self.bert = BertAdapterModel.from_pretrained(model_id)\n",
    "        # Insert adapter according to configuration\n",
    "        self.bert.add_adapter(task_id, config=self.adapter_config)\n",
    "        # Freeze all BERT-base weights \n",
    "        self.bert.train_adapter(task_id)\n",
    "        # Add prediction layer on top of BERT-base\n",
    "        self.bert.add_classification_head(task_id, num_labels=num_class)\n",
    "        # Make sure that adapters and prediction layer are used during forward pass\n",
    "        self.bert.set_active_adapters(task_id)\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3219b7ab-f64a-46aa-8a31-5d71b365dc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['heads.default.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2078786 || all params: 110418054 || trainable%: 1.8826504585925776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntrainable params: 1486658 || all params: 109796930 || trainable%: 1.3540068925424418\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model \n",
    "\n",
    "# task_id is the name of our adapter. You can name it whatever you want but\n",
    "# common practice is to name it according to task/dataset we will train it on.\n",
    "task_name = 'depression_reddit_dataset'\n",
    "model_adapter = BertClassifierWithAdapter(task_id=task_name)\n",
    "# Check parameters\n",
    "print_trainable_parameters(model_adapter)\n",
    "\n",
    "'''\n",
    "trainable params: 1486658 || all params: 109796930 || trainable%: 1.3540068925424418\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca694db1-5702-4cd7-9e1c-a01acc84cae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [03:04<00:00, 17.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.179             | Train Accuracy:  0.832             | Val Loss:  0.105             | Val Accuracy:  0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [03:08<00:00, 17.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.087             | Train Accuracy:  0.931             | Val Loss:  0.068             | Val Accuracy:  0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [03:08<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.053             | Train Accuracy:  0.961             | Val Loss:  0.046             | Val Accuracy:  0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [03:08<00:00, 17.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.043             | Train Accuracy:  0.967             | Val Loss:  0.047             | Val Accuracy:  0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [03:08<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.039             | Train Accuracy:  0.972             | Val Loss:  0.039             | Val Accuracy:  0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [03:08<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss:  0.035             | Train Accuracy:  0.976             | Val Loss:  0.027             | Val Accuracy:  0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [03:07<00:00, 17.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss:  0.031             | Train Accuracy:  0.977             | Val Loss:  0.037             | Val Accuracy:  0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [03:08<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss:  0.030             | Train Accuracy:  0.978             | Val Loss:  0.023             | Val Accuracy:  0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [03:08<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss:  0.026             | Train Accuracy:  0.981             | Val Loss:  0.050             | Val Accuracy:  0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3250/3250 [03:08<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 | Train Loss:  0.025             | Train Accuracy:  0.982             | Val Loss:  0.027             | Val Accuracy:  0.983\n"
     ]
    }
   ],
   "source": [
    "LR = 5e-6\n",
    "EPOCHS = 10\n",
    "train(model_adapter, dataset['train'][:6500], dataset['train'][6500:], LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298528f4-ea0d-48f3-859a-7365bae1df73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
