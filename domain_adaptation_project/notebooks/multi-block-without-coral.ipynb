{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/guest/Desktop/projects/intial-experments/domain_adaptation_project/notebooks', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/guest/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages', '/home/guest/Desktop/projects/intial-experments/domain_adaptation_project/modules']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/guest/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-04-26 06:10:03.843375: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-26 06:10:03.874137: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 06:10:04.376743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from setup import setup_src_path\n",
    "print(setup_src_path())\n",
    "import data.processed as processed\n",
    "import config.config as config\n",
    "import utils.setup as setup\n",
    "import utils.functions as fn\n",
    "from importlib import reload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "source_data=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/source_data\")\n",
    "source_data_eval=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/source_data_eval\")\n",
    "target_data=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/target_data\")\n",
    "target_data_eval=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/target_data_eval\")\n",
    "test_target_data=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/test_target_data\")\n",
    "unsupervised_target=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/unsupervised_target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_data = source_data.train_test_split(train_size=0.2, test_size=0.08)\n",
    "#source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "source_data_loader = DataLoader(source_data, batch_size=32, shuffle=True)\n",
    "target_data_loader = DataLoader(target_data, batch_size=32)\n",
    "source_data_eval_loader = DataLoader(source_data_eval, batch_size=32, shuffle=True)\n",
    "target_data_eval_loader = DataLoader(target_data_eval, batch_size=32)\n",
    "\n",
    "target_test_loader = DataLoader(test_target_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 66985530 || all params: 66985530 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "from adapters import AutoAdapterModel,init\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForMaskedLM\n",
    "\n",
    "mdlcfg = AutoConfig.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    " \n",
    ")\n",
    "model = AutoAdapterModel.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    ")\n",
    "reload(fn)\n",
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adapters.composition as ac\n",
    "\n",
    "#domain_adapter_coral = model.load_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/domain_adapter_telephone_travel\",with_head=False)\n",
    "mlm_adapter = model.load_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/standalone-mlm-target\",with_head=False)\n",
    "task_adapter = model.load_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/task_adapter\",with_head=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_adapter_fusion(ac.Fuse(mlm_adapter, task_adapter))\n",
    "model.add_classification_head(\"mnli\", num_labels=3)\n",
    "adapter_setup_fuse = ac.Fuse( mlm_adapter, task_adapter)\n",
    "model.train_adapter_fusion(adapter_setup_fuse)\n",
    "\n",
    "#model.active_adapters = ac.Stack(domain_adapter_coral, ac.Fuse(mlm_adapter, task_adapter))\n",
    "model.active_adapters = ac.Fuse(mlm_adapter, task_adapter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 11841597 || all params: 82197597 || trainable%: 14.406256912838948\n"
     ]
    }
   ],
   "source": [
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'standalone-mlm-target',\n",
       "  'architecture': 'bottleneck',\n",
       "  'active': True,\n",
       "  '#param': 3545856,\n",
       "  'train': False,\n",
       "  '%param': 4.605670051672885},\n",
       " {'name': 'task_adapter',\n",
       "  'architecture': 'bottleneck',\n",
       "  'active': True,\n",
       "  '#param': 447264,\n",
       "  'train': False,\n",
       "  '%param': 0.5809458731520459},\n",
       " {'name': 'Full model', '#param': 76988928, '%param': 100.0, 'train': False}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.adapter_summary(as_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertAdapterModel(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlockWithAdapters(\n",
       "          (attention): MultiHeadSelfAttentionWithAdapters(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): LoRALinear(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (k_lin): LoRALinear(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (v_lin): LoRALinear(\n",
       "              in_features=768, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (prefix_tuning): PrefixTuningLayer(\n",
       "              (prefix_gates): ModuleDict()\n",
       "              (pool): PrefixTuningPool(\n",
       "                (prefix_tunings): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): LoRALinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (lin2): LoRALinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (attention_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "          (output_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict(\n",
       "              (standalone-mlm-target): Adapter(\n",
       "                (non_linearity): Activation_Function_Class(\n",
       "                  (f): ReLU()\n",
       "                )\n",
       "                (adapter_down): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "                  (1): Activation_Function_Class(\n",
       "                    (f): ReLU()\n",
       "                  )\n",
       "                )\n",
       "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
       "              )\n",
       "              (task_adapter): Adapter(\n",
       "                (non_linearity): Activation_Function_Class(\n",
       "                  (f): ReLU()\n",
       "                )\n",
       "                (adapter_down): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                  (1): Activation_Function_Class(\n",
       "                    (f): ReLU()\n",
       "                  )\n",
       "                )\n",
       "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (adapter_fusion_layer): ModuleDict(\n",
       "              (standalone-mlm-target,task_adapter): BertFusion(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (invertible_adapters): ModuleDict()\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "    (prompt_tuning): PromptTuningLayer(\n",
       "      (base_model_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (prompt_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (heads): ModuleDict(\n",
       "    (default): BertStyleMaskedLMHead(\n",
       "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (1): Activation_Function_Class(\n",
       "        (f): GELUActivation()\n",
       "      )\n",
       "      (2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (3): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "    (mnli): ClassificationHead(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (2): Activation_Function_Class(\n",
       "        (f): Tanh()\n",
       "      )\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=768, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.query.weight\n",
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.query.bias\n",
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.key.weight\n",
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.key.bias\n",
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.value.weight\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.query.weight\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.query.bias\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.key.weight\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.key.bias\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.value.weight\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.query.weight\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.query.bias\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.key.weight\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.key.bias\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.value.weight\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.query.weight\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.query.bias\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.key.weight\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.key.bias\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.value.weight\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.query.weight\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.query.bias\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.key.weight\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.key.bias\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.value.weight\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.query.weight\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.query.bias\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.key.weight\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.key.bias\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.standalone-mlm-target,task_adapter.value.weight\n",
      "heads.default.0.weight\n",
      "heads.default.0.bias\n",
      "heads.default.2.weight\n",
      "heads.default.2.bias\n",
      "heads.default.3.bias\n",
      "heads.mnli.1.weight\n",
      "heads.mnli.1.bias\n",
      "heads.mnli.4.weight\n",
      "heads.mnli.4.bias\n",
      "Fuse[standalone-mlm-target, task_adapter]\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "print(model.active_adapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before adaptation: 0.2965587044534413\n",
      "F1 score before adaptation: 0.187969478812992\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the target domain before adaptation\n",
    "reload(fn)\n",
    "accuracy_before, f1_before = fn.evaluate_model(model, target_test_loader)\n",
    "print(f\"Accuracy before adaptation: {accuracy_before}\")\n",
    "print(f\"F1 score before adaptation: {f1_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9c5ee145b6471c9b155e715f844a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7598, 'learning_rate': 0.0001, 'epoch': 0.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef680125d71b45ecb9ea8fc0dbdfbc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8415830135345459, 'eval_accuracy': 0.6224951519069166, 'eval_f1': 0.616157178223111, 'eval_precision': 0.7213893782876665, 'eval_recall': 0.6224951519069166, 'eval_runtime': 16.0044, 'eval_samples_per_second': 483.306, 'eval_steps_per_second': 15.121, 'epoch': 0.21}\n",
      "{'loss': 0.6958, 'learning_rate': 9.436936936936938e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304be40180f64147a3fc0068f148ddc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7137276530265808, 'eval_accuracy': 0.6914027149321267, 'eval_f1': 0.6912552760946863, 'eval_precision': 0.7187909373806263, 'eval_recall': 0.6914027149321267, 'eval_runtime': 16.0964, 'eval_samples_per_second': 480.541, 'eval_steps_per_second': 15.034, 'epoch': 0.43}\n",
      "{'loss': 0.6876, 'learning_rate': 8.873873873873875e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7725c90abb4b769ad58d71c4233511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6969843506813049, 'eval_accuracy': 0.7045895281189399, 'eval_f1': 0.7036317058742353, 'eval_precision': 0.7159082961991664, 'eval_recall': 0.7045895281189399, 'eval_runtime': 16.1272, 'eval_samples_per_second': 479.626, 'eval_steps_per_second': 15.006, 'epoch': 0.64}\n",
      "{'loss': 0.6801, 'learning_rate': 8.310810810810811e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f38254c4ce542d8a0b04a57b0949471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7375524044036865, 'eval_accuracy': 0.6789915966386555, 'eval_f1': 0.6790238622074262, 'eval_precision': 0.7182350423625042, 'eval_recall': 0.6789915966386555, 'eval_runtime': 16.0985, 'eval_samples_per_second': 480.479, 'eval_steps_per_second': 15.032, 'epoch': 0.85}\n",
      "{'loss': 0.689, 'learning_rate': 7.747747747747748e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c021b00babcf4f0e870a907d332b4ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6886139512062073, 'eval_accuracy': 0.7122171945701358, 'eval_f1': 0.7127916454870203, 'eval_precision': 0.7187987913767446, 'eval_recall': 0.7122171945701358, 'eval_runtime': 16.0416, 'eval_samples_per_second': 482.183, 'eval_steps_per_second': 15.086, 'epoch': 1.07}\n",
      "{'loss': 0.6774, 'learning_rate': 7.184684684684685e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0a2de53c0e4fcfafb67c25165a5a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7316653728485107, 'eval_accuracy': 0.6775694893341953, 'eval_f1': 0.6775427816444346, 'eval_precision': 0.7176257636764025, 'eval_recall': 0.6775694893341953, 'eval_runtime': 16.1188, 'eval_samples_per_second': 479.874, 'eval_steps_per_second': 15.013, 'epoch': 1.28}\n",
      "{'loss': 0.6699, 'learning_rate': 6.621621621621621e-05, 'epoch': 1.49}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fad834431ee4a24b1cf37e0aa121255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7044363617897034, 'eval_accuracy': 0.6974789915966386, 'eval_f1': 0.6961769330839149, 'eval_precision': 0.7207352993698946, 'eval_recall': 0.6974789915966386, 'eval_runtime': 16.1186, 'eval_samples_per_second': 479.88, 'eval_steps_per_second': 15.014, 'epoch': 1.49}\n",
      "{'loss': 0.6669, 'learning_rate': 6.058558558558559e-05, 'epoch': 1.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2070b55a7caa49ea831203c453dc0943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6885243058204651, 'eval_accuracy': 0.7031674208144797, 'eval_f1': 0.7028064108236888, 'eval_precision': 0.7131921633461769, 'eval_recall': 0.7031674208144797, 'eval_runtime': 16.1289, 'eval_samples_per_second': 479.574, 'eval_steps_per_second': 15.004, 'epoch': 1.71}\n",
      "{'loss': 0.6663, 'learning_rate': 5.4954954954954966e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4534fed760f49ef8b4094d8faaef199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6806867718696594, 'eval_accuracy': 0.7154492566257272, 'eval_f1': 0.715237182859082, 'eval_precision': 0.7170525778001579, 'eval_recall': 0.7154492566257272, 'eval_runtime': 16.1344, 'eval_samples_per_second': 479.41, 'eval_steps_per_second': 14.999, 'epoch': 1.92}\n",
      "{'loss': 0.6693, 'learning_rate': 4.9324324324324325e-05, 'epoch': 2.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b01373263124e2997c38f2eb1f23cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.702130138874054, 'eval_accuracy': 0.7036845507433743, 'eval_f1': 0.7023498605700255, 'eval_precision': 0.7243858599246287, 'eval_recall': 0.7036845507433743, 'eval_runtime': 16.1322, 'eval_samples_per_second': 479.474, 'eval_steps_per_second': 15.001, 'epoch': 2.13}\n",
      "{'loss': 0.671, 'learning_rate': 4.369369369369369e-05, 'epoch': 2.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8d99f95fe54865a3755f10b19fd34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6812252402305603, 'eval_accuracy': 0.7107950872656755, 'eval_f1': 0.7110422441431065, 'eval_precision': 0.717050286901097, 'eval_recall': 0.7107950872656755, 'eval_runtime': 16.1274, 'eval_samples_per_second': 479.62, 'eval_steps_per_second': 15.006, 'epoch': 2.35}\n",
      "{'loss': 0.6533, 'learning_rate': 3.8063063063063064e-05, 'epoch': 2.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c5c201452c4105ace3710562f12720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7001863121986389, 'eval_accuracy': 0.709114414996768, 'eval_f1': 0.7058163486550327, 'eval_precision': 0.7235470926373643, 'eval_recall': 0.709114414996768, 'eval_runtime': 16.1123, 'eval_samples_per_second': 480.069, 'eval_steps_per_second': 15.02, 'epoch': 2.56}\n",
      "{'loss': 0.6526, 'learning_rate': 3.2432432432432436e-05, 'epoch': 2.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8eb159931884dfba3063040f4ef3c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7288534641265869, 'eval_accuracy': 0.6862314156431804, 'eval_f1': 0.6863435212689276, 'eval_precision': 0.718496800444309, 'eval_recall': 0.6862314156431804, 'eval_runtime': 16.0752, 'eval_samples_per_second': 481.175, 'eval_steps_per_second': 15.054, 'epoch': 2.77}\n",
      "{'loss': 0.6445, 'learning_rate': 2.6801801801801802e-05, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5608fda46ba4755ad0cff18fe34d4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6793242692947388, 'eval_accuracy': 0.7162249515190692, 'eval_f1': 0.7158333528605835, 'eval_precision': 0.7197940745192788, 'eval_recall': 0.7162249515190692, 'eval_runtime': 16.1162, 'eval_samples_per_second': 479.951, 'eval_steps_per_second': 15.016, 'epoch': 2.99}\n",
      "{'loss': 0.6575, 'learning_rate': 2.117117117117117e-05, 'epoch': 3.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ab6df87284449095034b437b2d0f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.696392834186554, 'eval_accuracy': 0.7045895281189399, 'eval_f1': 0.703753480118065, 'eval_precision': 0.7218227469095019, 'eval_recall': 0.7045895281189399, 'eval_runtime': 16.1285, 'eval_samples_per_second': 479.585, 'eval_steps_per_second': 15.004, 'epoch': 3.2}\n",
      "{'loss': 0.6491, 'learning_rate': 1.554054054054054e-05, 'epoch': 3.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5947ec750cc54a0c8480a3219c64219a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6902201771736145, 'eval_accuracy': 0.708338720103426, 'eval_f1': 0.7058682112659913, 'eval_precision': 0.7230742965141117, 'eval_recall': 0.708338720103426, 'eval_runtime': 16.1749, 'eval_samples_per_second': 478.211, 'eval_steps_per_second': 14.961, 'epoch': 3.41}\n",
      "{'loss': 0.6452, 'learning_rate': 9.90990990990991e-06, 'epoch': 3.62}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612b79d0245347a38499dc0104790b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6911162734031677, 'eval_accuracy': 0.7058823529411765, 'eval_f1': 0.7055692807855044, 'eval_precision': 0.7230116216665397, 'eval_recall': 0.7058823529411765, 'eval_runtime': 16.1503, 'eval_samples_per_second': 478.938, 'eval_steps_per_second': 14.984, 'epoch': 3.62}\n",
      "{'loss': 0.6416, 'learning_rate': 4.279279279279279e-06, 'epoch': 3.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e57e18526a43028f0289b60d44c1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6857745051383972, 'eval_accuracy': 0.7097608274078863, 'eval_f1': 0.7087684757794204, 'eval_precision': 0.7234510751705419, 'eval_recall': 0.7097608274078863, 'eval_runtime': 16.1585, 'eval_samples_per_second': 478.694, 'eval_steps_per_second': 14.977, 'epoch': 3.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting existing adapter 'standalone-mlm-target'.\n",
      "Overwriting existing adapter 'task_adapter'.\n",
      "Overwriting existing adapter fusion module 'standalone-mlm-target,task_adapter'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1634.5757, 'train_samples_per_second': 183.566, 'train_steps_per_second': 5.738, 'train_loss': 0.6693706764595341, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reload(fn)\n",
    "trainer = fn.train_model(model,\"multi_block-without-coral\",source_data,source_data_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before adaptation: 0.6938259109311741\n",
      "F1 score before adaptation: 0.6944925204457613\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the target domain before adaptation\n",
    "reload(fn)\n",
    "accuracy_before, f1_before = fn.evaluate_model(trainer.model, target_test_loader)\n",
    "print(f\"Accuracy before adaptation: {accuracy_before}\")\n",
    "print(f\"F1 score before adaptation: {f1_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before adaptation: 0.7211538461538461\n",
      "F1 score before adaptation: 0.7214558115652716\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the target domain before adaptation\n",
    "#this is using the full sourcec domain data\n",
    "reload(fn)\n",
    "accuracy_before, f1_before = fn.evaluate_model(trainer.model, target_test_loader)\n",
    "print(f\"Accuracy before adaptation: {accuracy_before}\")\n",
    "print(f\"F1 score before adaptation: {f1_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before adaptation: 0.7186234817813765\n",
      "F1 score before adaptation: 0.7189379678534682\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the target domain before adaptation\n",
    "#final\n",
    "reload(fn)\n",
    "accuracy_before, f1_before = fn.evaluate_model(trainer.model, target_test_loader)\n",
    "print(f\"Accuracy before adaptation: {accuracy_before}\")\n",
    "print(f\"F1 score before adaptation: {f1_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intial-experments-_CPDD38x-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
