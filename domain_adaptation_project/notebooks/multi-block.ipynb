{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/guest/Desktop/projects/intial-experments/domain_adaptation_project/notebooks', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/guest/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages', '/home/guest/Desktop/projects/intial-experments/domain_adaptation_project/modules']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/guest/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-03-21 21:26:50.978492: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 21:26:51.009489: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-21 21:26:51.532095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from setup import setup_src_path\n",
    "print(setup_src_path())\n",
    "import data.processed as processed\n",
    "import config.config as config\n",
    "import utils.setup as setup\n",
    "import utils.functions as fn\n",
    "from importlib import reload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "source_data=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/source_data\")\n",
    "source_data_eval=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/source_data_eval\")\n",
    "target_data=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/target_data\")\n",
    "target_data_eval=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/target_data_eval\")\n",
    "test_target_data=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/test_target_data\")\n",
    "unsupervised_target=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/unsupervised_target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "source_data_loader = DataLoader(source_data, batch_size=32, shuffle=True)\n",
    "target_data_loader = DataLoader(target_data, batch_size=32)\n",
    "source_data_eval_loader = DataLoader(source_data_eval, batch_size=32, shuffle=True)\n",
    "target_data_eval_loader = DataLoader(target_data_eval, batch_size=32)\n",
    "\n",
    "target_test_loader = DataLoader(test_target_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 66985530 || all params: 66985530 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "from adapters import AutoAdapterModel,init\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForMaskedLM\n",
    "\n",
    "mdlcfg = AutoConfig.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    " \n",
    ")\n",
    "model = AutoAdapterModel.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    ")\n",
    "reload(fn)\n",
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adapters.composition as ac\n",
    "\n",
    "domain_adapter_coral = model.load_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/domain_adapter_telephone_travel\",with_head=False)\n",
    "mlm_adapter = model.load_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/mlm-after-coral\",with_head=False)\n",
    "task_adapter = model.load_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/stacked-adapter-task-modefied\",with_head=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_adapter_fusion(ac.Fuse(mlm_adapter, task_adapter))\n",
    "model.add_classification_head(\"mnli\", num_labels=3)\n",
    "adapter_setup_fuse = ac.Fuse( mlm_adapter, task_adapter)\n",
    "model.train_adapter_fusion(adapter_setup_fuse)\n",
    "\n",
    "model.active_adapters = ac.Stack(domain_adapter_coral, ac.Fuse(mlm_adapter, task_adapter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 11841597 || all params: 82644861 || trainable%: 14.32829199144034\n"
     ]
    }
   ],
   "source": [
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.weight\n",
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.bias\n",
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.weight\n",
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.bias\n",
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.value.weight\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.weight\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.bias\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.weight\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.bias\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.value.weight\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.weight\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.bias\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.weight\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.bias\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.value.weight\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.weight\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.bias\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.weight\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.bias\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.value.weight\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.weight\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.bias\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.weight\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.bias\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.value.weight\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.weight\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.bias\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.weight\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.bias\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.value.weight\n",
      "heads.default.0.weight\n",
      "heads.default.0.bias\n",
      "heads.default.2.weight\n",
      "heads.default.2.bias\n",
      "heads.default.3.bias\n",
      "heads.mnli.1.weight\n",
      "heads.mnli.1.bias\n",
      "heads.mnli.4.weight\n",
      "heads.mnli.4.bias\n",
      "Stack[domain_adapter_telephone-travel, Fuse[mlm-after-coral, stacked-adapter-task-modefied]]\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "print(model.active_adapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before adaptation: 0.30465587044534415\n",
      "F1 score before adaptation: 0.26615970008818535\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the target domain before adaptation\n",
    "reload(fn)\n",
    "accuracy_before, f1_before = fn.evaluate_model(model, target_test_loader)\n",
    "print(f\"Accuracy before adaptation: {accuracy_before}\")\n",
    "print(f\"F1 score before adaptation: {f1_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72b3e1e8f0b48c5bafe90eff132ac14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6897, 'learning_rate': 0.0001, 'epoch': 0.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1630c1cfb45c46cd8887f407c9095f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7791772484779358, 'eval_accuracy': 0.664382676147382, 'eval_f1': 0.66311905584895, 'eval_precision': 0.7322760128787381, 'eval_recall': 0.664382676147382, 'eval_runtime': 16.3222, 'eval_samples_per_second': 473.896, 'eval_steps_per_second': 14.826, 'epoch': 0.21}\n",
      "{'loss': 0.6186, 'learning_rate': 9.436936936936938e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb654644d5a442882ae12f866f503c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6726610660552979, 'eval_accuracy': 0.7131221719457014, 'eval_f1': 0.7141608258534596, 'eval_precision': 0.7251631544885055, 'eval_recall': 0.7131221719457014, 'eval_runtime': 16.4226, 'eval_samples_per_second': 470.998, 'eval_steps_per_second': 14.736, 'epoch': 0.43}\n",
      "{'loss': 0.605, 'learning_rate': 8.873873873873875e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b177ebe5e76b43218c426b51e71a2481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6821749210357666, 'eval_accuracy': 0.7157078215901745, 'eval_f1': 0.7152015822443234, 'eval_precision': 0.7255129325090356, 'eval_recall': 0.7157078215901745, 'eval_runtime': 16.502, 'eval_samples_per_second': 468.731, 'eval_steps_per_second': 14.665, 'epoch': 0.64}\n",
      "{'loss': 0.6006, 'learning_rate': 8.310810810810811e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3036d85d58498d9845a92476b13c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7660184502601624, 'eval_accuracy': 0.6686489980607627, 'eval_f1': 0.6672343965072558, 'eval_precision': 0.7218941209493576, 'eval_recall': 0.6686489980607627, 'eval_runtime': 16.4768, 'eval_samples_per_second': 469.448, 'eval_steps_per_second': 14.687, 'epoch': 0.85}\n",
      "{'loss': 0.6016, 'learning_rate': 7.747747747747748e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e6bc44368844668e11cb77a3f3fbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6626256108283997, 'eval_accuracy': 0.7229476405946994, 'eval_f1': 0.7237490310920451, 'eval_precision': 0.7287222314031658, 'eval_recall': 0.7229476405946994, 'eval_runtime': 16.4923, 'eval_samples_per_second': 469.006, 'eval_steps_per_second': 14.673, 'epoch': 1.07}\n",
      "{'loss': 0.6012, 'learning_rate': 7.184684684684685e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0a2c7a5b4e47eda1a451396d24fa35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7244648933410645, 'eval_accuracy': 0.6782159017453135, 'eval_f1': 0.6774811332435501, 'eval_precision': 0.7233151178973699, 'eval_recall': 0.6782159017453135, 'eval_runtime': 16.4832, 'eval_samples_per_second': 469.264, 'eval_steps_per_second': 14.682, 'epoch': 1.28}\n",
      "{'loss': 0.5964, 'learning_rate': 6.621621621621621e-05, 'epoch': 1.49}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0d974875a548139e37814f01dbaebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6844918131828308, 'eval_accuracy': 0.7114414996767938, 'eval_f1': 0.7124098953652562, 'eval_precision': 0.7308140858026748, 'eval_recall': 0.7114414996767938, 'eval_runtime': 16.5171, 'eval_samples_per_second': 468.302, 'eval_steps_per_second': 14.651, 'epoch': 1.49}\n",
      "{'loss': 0.59, 'learning_rate': 6.058558558558559e-05, 'epoch': 1.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b6865f6d7a4a99a39580bcce525088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.659591019153595, 'eval_accuracy': 0.7221719457013575, 'eval_f1': 0.722742991675605, 'eval_precision': 0.7298846243793242, 'eval_recall': 0.7221719457013575, 'eval_runtime': 16.5167, 'eval_samples_per_second': 468.315, 'eval_steps_per_second': 14.652, 'epoch': 1.71}\n",
      "{'loss': 0.5845, 'learning_rate': 5.4954954954954966e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732748bc10d440d3884969670e5ca69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6669735312461853, 'eval_accuracy': 0.7244990303813833, 'eval_f1': 0.7254137678241873, 'eval_precision': 0.7296191650072317, 'eval_recall': 0.7244990303813833, 'eval_runtime': 16.5193, 'eval_samples_per_second': 468.239, 'eval_steps_per_second': 14.65, 'epoch': 1.92}\n",
      "{'loss': 0.589, 'learning_rate': 4.9324324324324325e-05, 'epoch': 2.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa3cc356d4a4abeb677ff7be366f6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.676594078540802, 'eval_accuracy': 0.713639301874596, 'eval_f1': 0.7136485256031807, 'eval_precision': 0.7348411587764859, 'eval_recall': 0.713639301874596, 'eval_runtime': 16.5057, 'eval_samples_per_second': 468.625, 'eval_steps_per_second': 14.662, 'epoch': 2.13}\n",
      "{'loss': 0.5917, 'learning_rate': 4.369369369369369e-05, 'epoch': 2.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30e83d96d00419abceea63c3c08c468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6771166920661926, 'eval_accuracy': 0.7157078215901745, 'eval_f1': 0.7164124788602109, 'eval_precision': 0.7271279623628554, 'eval_recall': 0.7157078215901745, 'eval_runtime': 16.4945, 'eval_samples_per_second': 468.943, 'eval_steps_per_second': 14.672, 'epoch': 2.35}\n",
      "{'loss': 0.5686, 'learning_rate': 3.8063063063063064e-05, 'epoch': 2.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f786b0f94644977bf0fd4b4673dec39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6631783246994019, 'eval_accuracy': 0.7265675500969618, 'eval_f1': 0.7258428716828988, 'eval_precision': 0.7334578183671479, 'eval_recall': 0.7265675500969618, 'eval_runtime': 16.4605, 'eval_samples_per_second': 469.914, 'eval_steps_per_second': 14.702, 'epoch': 2.56}\n",
      "{'loss': 0.573, 'learning_rate': 3.2432432432432436e-05, 'epoch': 2.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243476befd2e456b9803d35e7fa74ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7078338265419006, 'eval_accuracy': 0.7044602456367163, 'eval_f1': 0.7051978381598859, 'eval_precision': 0.7287264090068369, 'eval_recall': 0.7044602456367163, 'eval_runtime': 16.4345, 'eval_samples_per_second': 470.655, 'eval_steps_per_second': 14.725, 'epoch': 2.77}\n",
      "{'loss': 0.5643, 'learning_rate': 2.6801801801801802e-05, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f17a1ff7d14cbab9915da47300d202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6542946100234985, 'eval_accuracy': 0.7268261150614092, 'eval_f1': 0.7274317619725337, 'eval_precision': 0.729621445928122, 'eval_recall': 0.7268261150614092, 'eval_runtime': 16.4224, 'eval_samples_per_second': 471.003, 'eval_steps_per_second': 14.736, 'epoch': 2.99}\n",
      "{'loss': 0.5711, 'learning_rate': 2.117117117117117e-05, 'epoch': 3.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f4134d81fb4e8c83f63a31a0ef109a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6673423647880554, 'eval_accuracy': 0.7239819004524887, 'eval_f1': 0.7240729271088103, 'eval_precision': 0.7382945437876084, 'eval_recall': 0.7239819004524887, 'eval_runtime': 16.4889, 'eval_samples_per_second': 469.103, 'eval_steps_per_second': 14.677, 'epoch': 3.2}\n",
      "{'loss': 0.5652, 'learning_rate': 1.554054054054054e-05, 'epoch': 3.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f013f13a0443f2a251a9a62ca9d777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6654248237609863, 'eval_accuracy': 0.724240465416936, 'eval_f1': 0.7239100387311882, 'eval_precision': 0.7382720534757281, 'eval_recall': 0.724240465416936, 'eval_runtime': 16.5307, 'eval_samples_per_second': 467.918, 'eval_steps_per_second': 14.639, 'epoch': 3.41}\n",
      "{'loss': 0.5621, 'learning_rate': 9.90990990990991e-06, 'epoch': 3.62}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696a2b7cbdf84ae983323e9cdd2304e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6697875261306763, 'eval_accuracy': 0.7182934712346477, 'eval_f1': 0.7191760574617739, 'eval_precision': 0.7326696435728212, 'eval_recall': 0.7182934712346477, 'eval_runtime': 16.5176, 'eval_samples_per_second': 468.289, 'eval_steps_per_second': 14.651, 'epoch': 3.62}\n",
      "{'loss': 0.5553, 'learning_rate': 4.279279279279279e-06, 'epoch': 3.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f805caa98b6e4d66bba95604383884d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.666977047920227, 'eval_accuracy': 0.7235940530058177, 'eval_f1': 0.7240943111865201, 'eval_precision': 0.7394325887248321, 'eval_recall': 0.7235940530058177, 'eval_runtime': 16.4934, 'eval_samples_per_second': 468.976, 'eval_steps_per_second': 14.673, 'epoch': 3.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting existing adapter 'domain_adapter_telephone-travel'.\n",
      "Overwriting existing adapter 'mlm-after-coral'.\n",
      "Overwriting existing adapter 'stacked-adapter-task-modefied'.\n",
      "Overwriting existing adapter fusion module 'mlm-after-coral,stacked-adapter-task-modefied'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1666.2641, 'train_samples_per_second': 180.075, 'train_steps_per_second': 5.629, 'train_loss': 0.5890023318943438, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reload(fn)\n",
    "trainer = fn.train_model(model,\"multi_block\",source_data,target_data_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before adaptation: 0.7130566801619433\n",
      "F1 score before adaptation: 0.7149068389081805\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the target domain before adaptation\n",
    "reload(fn)\n",
    "accuracy_before, f1_before = fn.evaluate_model(trainer.model, target_test_loader)\n",
    "print(f\"Accuracy before adaptation: {accuracy_before}\")\n",
    "print(f\"F1 score before adaptation: {f1_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intial-experments-_CPDD38x-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
