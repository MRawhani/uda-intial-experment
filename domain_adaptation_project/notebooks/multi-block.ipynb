{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/guest/Desktop/projects/intial-experments/domain_adaptation_project/notebooks', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/guest/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages', '/home/guest/Desktop/projects/intial-experments/domain_adaptation_project/modules']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/guest/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-04-26 06:04:17.288378: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-26 06:04:17.501021: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 06:04:18.186634: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from setup import setup_src_path\n",
    "print(setup_src_path())\n",
    "import data.processed as processed\n",
    "import config.config as config\n",
    "import utils.setup as setup\n",
    "import utils.functions as fn\n",
    "from importlib import reload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "source_data=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/source_data\")\n",
    "source_data_eval=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/source_data_eval\")\n",
    "target_data=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/target_data\")\n",
    "target_data_eval=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/target_data_eval\")\n",
    "test_target_data=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/test_target_data\")\n",
    "unsupervised_target=load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/unsupervised_target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "source_data_loader = DataLoader(source_data, batch_size=32, shuffle=True)\n",
    "target_data_loader = DataLoader(target_data, batch_size=32)\n",
    "source_data_eval_loader = DataLoader(source_data_eval, batch_size=32, shuffle=True)\n",
    "target_data_eval_loader = DataLoader(target_data_eval, batch_size=32)\n",
    "\n",
    "target_test_loader = DataLoader(test_target_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 66985530 || all params: 66985530 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "from adapters import AutoAdapterModel,init\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForMaskedLM\n",
    "\n",
    "mdlcfg = AutoConfig.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    " \n",
    ")\n",
    "model = AutoAdapterModel.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    ")\n",
    "reload(fn)\n",
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adapters.composition as ac\n",
    "\n",
    "domain_adapter_coral = model.load_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/domain_adapter_telephone_travel\",with_head=False)\n",
    "mlm_adapter = model.load_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/mlm-after-coral\",with_head=False)\n",
    "task_adapter = model.load_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/stacked-adapter-task-modefied\",with_head=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_adapter_fusion(ac.Fuse(mlm_adapter, task_adapter))\n",
    "model.add_classification_head(\"mnli\", num_labels=3)\n",
    "adapter_setup_fuse = ac.Fuse( mlm_adapter, task_adapter)\n",
    "model.train_adapter_fusion(adapter_setup_fuse)\n",
    "\n",
    "#model.active_adapters = ac.Stack(domain_adapter_coral, ac.Fuse(mlm_adapter, task_adapter))\n",
    "model.active_adapters = ac.Fuse(mlm_adapter, task_adapter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 11841597 || all params: 82644861 || trainable%: 14.32829199144034\n"
     ]
    }
   ],
   "source": [
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'domain_adapter_telephone-travel',\n",
       "  'architecture': 'bottleneck',\n",
       "  'active': False,\n",
       "  '#param': 447264,\n",
       "  'train': False,\n",
       "  '%param': 0.5809458731520459},\n",
       " {'name': 'mlm-after-coral',\n",
       "  'architecture': 'bottleneck',\n",
       "  'active': True,\n",
       "  '#param': 3545856,\n",
       "  'train': False,\n",
       "  '%param': 4.605670051672885},\n",
       " {'name': 'stacked-adapter-task-modefied',\n",
       "  'architecture': 'bottleneck',\n",
       "  'active': True,\n",
       "  '#param': 447264,\n",
       "  'train': False,\n",
       "  '%param': 0.5809458731520459},\n",
       " {'name': 'Full model', '#param': 76988928, '%param': 100.0, 'train': False}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.adapter_summary(as_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.weight\n",
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.bias\n",
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.weight\n",
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.bias\n",
      "distilbert.transformer.layer.0.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.value.weight\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.weight\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.bias\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.weight\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.bias\n",
      "distilbert.transformer.layer.1.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.value.weight\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.weight\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.bias\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.weight\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.bias\n",
      "distilbert.transformer.layer.2.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.value.weight\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.weight\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.bias\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.weight\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.bias\n",
      "distilbert.transformer.layer.3.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.value.weight\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.weight\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.bias\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.weight\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.bias\n",
      "distilbert.transformer.layer.4.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.value.weight\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.weight\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.query.bias\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.weight\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.key.bias\n",
      "distilbert.transformer.layer.5.output_adapters.adapter_fusion_layer.mlm-after-coral,stacked-adapter-task-modefied.value.weight\n",
      "heads.default.0.weight\n",
      "heads.default.0.bias\n",
      "heads.default.2.weight\n",
      "heads.default.2.bias\n",
      "heads.default.3.bias\n",
      "heads.mnli.1.weight\n",
      "heads.mnli.1.bias\n",
      "heads.mnli.4.weight\n",
      "heads.mnli.4.bias\n",
      "Fuse[mlm-after-coral, stacked-adapter-task-modefied]\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "print(model.active_adapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before adaptation: 0.37955465587044535\n",
      "F1 score before adaptation: 0.379429807529451\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the target domain before adaptation\n",
    "reload(fn)\n",
    "accuracy_before, f1_before = fn.evaluate_model(model, target_test_loader)\n",
    "print(f\"Accuracy before adaptation: {accuracy_before}\")\n",
    "print(f\"F1 score before adaptation: {f1_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b3049dc2a4406db9b124411a3c940f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7055, 'learning_rate': 0.0001, 'epoch': 0.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf7e08dd56542b88d2edf8ec1adb8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8023195266723633, 'eval_accuracy': 0.6519715578539108, 'eval_f1': 0.6505233334371221, 'eval_precision': 0.7202749221307585, 'eval_recall': 0.6519715578539108, 'eval_runtime': 15.5309, 'eval_samples_per_second': 498.04, 'eval_steps_per_second': 15.582, 'epoch': 0.21}\n",
      "{'loss': 0.62, 'learning_rate': 9.436936936936938e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94316a94430435680479f6ba09f52b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6790050268173218, 'eval_accuracy': 0.7100193923723336, 'eval_f1': 0.7109180774214868, 'eval_precision': 0.724771451692845, 'eval_recall': 0.7100193923723336, 'eval_runtime': 15.8187, 'eval_samples_per_second': 488.978, 'eval_steps_per_second': 15.298, 'epoch': 0.43}\n",
      "{'loss': 0.608, 'learning_rate': 8.873873873873875e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbd7c27627e48c980a6e5a1fc97bde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6839444637298584, 'eval_accuracy': 0.7142857142857143, 'eval_f1': 0.7141066378849438, 'eval_precision': 0.724784604402491, 'eval_recall': 0.7142857142857143, 'eval_runtime': 16.0477, 'eval_samples_per_second': 481.999, 'eval_steps_per_second': 15.08, 'epoch': 0.64}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m reload(fn)\n\u001b[0;32m----> 2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmulti_block\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msource_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43msource_data_eval\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/intial-experments/domain_adaptation_project/modules/utils/functions.py:84\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, prepended_path, train_data, eval_data)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: acc,\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m: f1,\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: precision,\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: recall\n\u001b[1;32m     77\u001b[0m     }\n\u001b[1;32m     78\u001b[0m trainer \u001b[38;5;241m=\u001b[39m AdapterTrainer(\n\u001b[1;32m     79\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,                           \u001b[38;5;66;03m# The instantiated 🤗 Transformers model to be trained\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,                    \u001b[38;5;66;03m# Training arguments, defined above\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_data,           \u001b[38;5;66;03m# Training dataset\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39meval_data \u001b[38;5;28;01mif\u001b[39;00m eval_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     83\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics \u001b[38;5;28;01mif\u001b[39;00m eval_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m    )\n\u001b[0;32m---> 84\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages/transformers/trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/intial-experments-_CPDD38x-py3.8/lib/python3.8/site-packages/transformers/trainer.py:1856\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   1854\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m-> 1856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1857\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1859\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1860\u001b[0m ):\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "reload(fn)\n",
    "trainer = fn.train_model(model,\"multi_block\",source_data,source_data_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before adaptation: 0.7160931174089069\n",
      "F1 score before adaptation: 0.7176271232227095\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the target domain before adaptation\n",
    "reload(fn)\n",
    "accuracy_before, f1_before = fn.evaluate_model(trainer.model, target_test_loader)\n",
    "print(f\"Accuracy before adaptation: {accuracy_before}\")\n",
    "print(f\"F1 score before adaptation: {f1_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before adaptation: 0.7130566801619433\n",
      "F1 score before adaptation: 0.7149068389081805\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the target domain before adaptation\n",
    "# this was with coral, it means before last edit. see the commented line above\n",
    "reload(fn)\n",
    "accuracy_before, f1_before = fn.evaluate_model(trainer.model, target_test_loader)\n",
    "print(f\"Accuracy before adaptation: {accuracy_before}\")\n",
    "print(f\"F1 score before adaptation: {f1_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intial-experments-_CPDD38x-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
